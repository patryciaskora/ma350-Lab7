---
title: "Lab 7"
author: "Patricia Skora and Odalys Barrientos"
output: html_notebook
---

# Lab 7: Five Scored and Several Months Ago

## Part I: Import and Look
### Problem 1
```{r}
quiz <- read.csv('quiz.csv')
```

### Problem 2
```{r}
plot(quiz)
```
The students' scores across quizzes do appear to be associated in the way that as more quizzes were taken, the scores seemed to be better. There are also more clusters in the plots than there are outliers, indicating that students are scoring around the same range.

## Part II: Every Quiz Is Exactly The same?
### Problem 3
```{r}
quiz2 <- quiz[,1]
quiz6 <- quiz[,5]
plot(quiz2, quiz6, main = "Quiz 2 vs Quiz 6")
```

### Problem 4
```{r}
?cor #Pearson correlation is the default for cor()
cor(quiz2, quiz6)
```
After running the Pearson correlation test using cor(), the correlation value is about .490 which is a positive association between the quiz percentages.

### Problem 5
```{r}
#' A function that generates bootstrap estimates of the Pearson correlation between two vectors.
#'
#' @param x A vector.
#' @param y A vector.
#' @param B The number of bootstrap estimates of the Pearson correlation with a default value of 2000.
#'
#' @returns The B boostrap estimates of the Pearson correlation.

bootstrap.cor <- function(x, y, B = 2000){
  samples.index <- replicate(B, sample(length(x), replace=TRUE))
  bootstrap.cors <- vector()
  for(i in 1:B){
  k <- samples.index[,i]
  bootstrap.cors[i] <- cor(x[k], y[k])
  }
  return(bootstrap.cors)
}

```

### Problem 6
```{r}
boot.estimates <- bootstrap.cor(x=quiz2, y=quiz6, B=5000)
hist(boot.estimates, breaks="FD")
```
The bootstrap estimates fall under a bell curve where the majority of the estimates falls under the 0.4 to the 0.6 range and where the left tail seems a little heavier than the right tail. 

### Problem 7
```{r}
quantile(boot.estimates, c(0.025,0.975))
cor.test(quiz2,quiz6, conf.level = 0.95)
```
These confidence intervals are close however, the quantile function does not cover as much information as cor.test. Yes, we can reject the null with significance level 0.05. The null claims that there is no association between quiz 2 and quiz 6 but 0 does not fall on the confidence interval so this indicates there could be an assocaition between quiz 2 and quiz 6. 

## Part III: The "It" Factor
### Problem 8
```{r}
cov.mat <- cov(quiz)
cov.mat
cov.mat[1,2] # (1,2) entry
quiz3 <- quiz[,2]
cov(quiz2, quiz3) 
```
The (1,2) entry in cov.mat matches the covariance you get when you calculate quiz2 and quiz3's covariance using cov(), being 230.7018.

### Problem 9
```{r}
eigen.vals <- eigen(cov.mat)$values
eigen.vals
```
These eigen values are sorted from largest eigen value to the smallest eigen value. 

### Problem 10
```{r}
sum(eigen.vals) 
sum(diag(cov.mat))
```

### Problem 11 
```{r}
eigenratio <- eigen.vals[1]/sum(eigen.vals)
eigenratio
```
The proportion of the variance captured by the first principal component is .64.

### Problem 12
```{r}
#' A function that generates bootstrap estimates of the eigenratio useing the case resampling
#' bootstrap on a data frame.
#' 
#' @params mat A data frame.
#' @params B The number of bootstrap samples to generate, with a default value of 2000.
#'
#' @returns The B bootstrap estimates of the eigenratio.
bootstrap.eigenratio <- function(mat, B = 2000){
  vals <- replicate(B,mat[sample(1:nrow(mat), replace = TRUE),])
  return(vals)
}
bootstrap.eigenratio(quiz)
```

### Problem 13
```{r}

```

